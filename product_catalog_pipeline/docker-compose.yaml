services:
  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    ports:
      - "5432:5432"
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data

  airflow-init:
    image: apache/airflow:2.9.0
    depends_on:
      - postgres
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__CORE__FERNET_KEY: "FjmFNmDvXHFYhexRG90xYu51_sdvr9WFSZk1Mqhhh9I="
      AIRFLOW__WEBSERVER__SECRET_KEY: "FjmFNmDvXHFYhexRG90xYu51_sdvr9WFSZk1Mqhhh9I="
      _PIP_ADDITIONAL_REQUIREMENTS: >-
        apache-airflow-providers-snowflake==5.3.1
        apache-airflow-providers-amazon==8.19.0
        apache-airflow-providers-common-sql==1.11.1
        apache-airflow-providers-docker>=3.7.0
        snowflake-connector-python
    user: "0:0"
    command: bash -c "airflow db init"
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./dbt:/opt/airflow/dbt
      - app_data:/usr/app

  webserver:
    image: apache/airflow:2.9.0
    depends_on:
      - airflow-init
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__CORE__FERNET_KEY: "FjmFNmDvXHFYhexRG90xYu51_sdvr9WFSZk1Mqhhh9I="
      AIRFLOW__WEBSERVER__RBAC: "true"
      AIRFLOW__WEBSERVER__SECRET_KEY: "FjmFNmDvXHFYhexRG90xYu51_sdvr9WFSZk1Mqhhh9I="
      _PIP_ADDITIONAL_REQUIREMENTS: >-
        apache-airflow-providers-snowflake==5.3.1
        apache-airflow-providers-amazon==8.19.0
        apache-airflow-providers-common-sql==1.11.1
        apache-airflow-providers-docker>=3.7.0
      # Optional: only used if you run dbt manually via `docker compose run dbt`
      SF_ACCOUNT: EAFJVKZ-XEB20360
      SF_USER: Rohil
      SF_PASSWORD: RohilUtture123$
      SF_ROLE: SYSADMIN
      SF_WAREHOUSE: COMPUTE_WH
    ports:
      - "8080:8080"
    command: webserver
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./dbt:/opt/airflow/dbt
      - app_data:/usr/app

  scheduler:
    image: apache/airflow:2.9.0
    depends_on:
      - airflow-init
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__CORE__FERNET_KEY: "FjmFNmDvXHFYhexRG90xYu51_sdvr9WFSZk1Mqhhh9I="
      AIRFLOW__WEBSERVER__SECRET_KEY: "FjmFNmDvXHFYhexRG90xYu51_sdvr9WFSZk1Mqhhh9I="
      _PIP_ADDITIONAL_REQUIREMENTS: >-
        apache-airflow-providers-snowflake==5.3.1
        apache-airflow-providers-amazon==8.19.0
        apache-airflow-providers-common-sql==1.11.1
        apache-airflow-providers-docker>=3.7.0
      # Optional: only used if you run dbt manually via `docker compose run dbt`
      SF_ACCOUNT: EAFJVKZ-XEB20360
      SF_USER: Rohil
      SF_PASSWORD: RohilUtture123$
      SF_ROLE: SYSADMIN
      SF_WAREHOUSE: COMPUTE_WH
    command: scheduler
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./dbt:/opt/airflow/dbt
      - app_data:/usr/app
      - /var/run/docker.sock:/var/run/docker.sock  # DockerOperator needs this

  dbt:
    image: ghcr.io/dbt-labs/dbt-snowflake:1.7.2
    working_dir: /usr/app/dbt/product_catalog
    environment:
      SF_ACCOUNT: EAFJVKZ-XEB20360
      SF_USER: Rohil
      SF_PASSWORD: "RohilUtture123$"
      SF_ROLE: SYSADMIN
      SF_WAREHOUSE: COMPUTE_WH
      DBT_PROFILES_DIR: /usr/app/dbt
    volumes:
      - app_data:/usr/app

volumes:
  postgres-db-volume:
  app_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./
